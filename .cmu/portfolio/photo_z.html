<html>
    <head>
        <!-- Mobile Specific Meta -->
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- Always force latest IE rendering engine -->
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <!-- Meta Keyword -->
        <meta name="keywords" content="one page, business template, single page, onepage, responsive, parallax, creative, business, html5, css3, css3 animation">
        <!-- meta character set -->
        <meta charset="utf-8">

        <!-- Site Title -->
        <title>Alankar Kotwal</title>
        
        <!--
        Google Fonts
        ============================================= -->
        <link href="http://fonts.googleapis.com/css?family=Open+Sans:400,300,600,700" rel="stylesheet" type="text/css">
		
        <!--
        CSS
        ============================================= -->
        <!-- Fontawesome -->
        <link rel="stylesheet" href="../css/font-awesome.min.css">
        <!-- Bootstrap -->
        <link rel="stylesheet" href="../css/bootstrap.min.css">
        <!-- Fancybox -->
        <link rel="stylesheet" href="../css/jquery.fancybox.css">
        <!-- owl carousel -->
        <link rel="stylesheet" href="../css/owl.carousel.css">
        <!-- Animate -->
        <link rel="stylesheet" href="../css/animate.css">
        <!-- Main Stylesheet -->
        <link rel="stylesheet" href="../css/main.css">
        <!-- Main Responsive -->
        <link rel="stylesheet" href="../css/responsive.css">
		
		
	<!-- Modernizer Script for old Browsers -->
        <script src="js/vendor/modernizr-2.6.2.min.js"></script>
	<script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.4/jquery.min.js"></script>
	<script type="text/javascript" src="http://fancyapps.com/fancybox/source/jquery.fancybox.js"></script>
	<script type="text/javascript">
	    $(document).ready(function() {
	        $(".iframe").fancybox({
	            type: 'iframe'
		});
	    });
	</script>
		
	<style>
	.black_overlay{
	    display: none;
	    position: absolute;
	    top: 0%;
	    left: 0%;
	    width: 100%;
	    height: 100%;
	    background-color: black;
	    z-index:1001;
	    -moz-opacity: 0.8;
	    opacity:.80;
	    filter: alpha(opacity=80);
	}
	.white_content {
	    display: none;
	    position: absolute;
	    top: 25%;
	    left: 25%;
	    width: 50%;
	    height: 50%;
	    padding: 16px;
	    border: 16px solid #00C7FC;
	    background-color: white;
	    z-index:1002;
	    overflow: auto;
	}
	</style>
    </head>
    <body>
        <br /> <br />
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <div class="section-title text-center wow fadeInDown">
                        <h2>Image Pixel Based Photometric Redshift Estimation</h2> 
    		        <br />
                        <h4>Guide: Prof. Robert Brunner, Astronomy, University of Illinois at Urbana&#8212;Champaign</h4> 
    		        <br />
                        <p style="FONT-SIZE:16px; COLOR:black; LINE-HEIGHT:20px; TEXT-ALIGN:justify;">
    		        Current techniques for photometric redshift estimation rely upon reduced integrated information from
			images. The features used as data in the algorithm are primarily the integrated flux from the object under
			consideration in various color filters, from which the algorithm calculates the photo-z for the object. The
			photo-z as an estimate for the actual redshift gives the distance to the object within a certain error. The
			information that is thus wasted on a pixel level can be made use of in order to get a more accurate estimate
			of the photo-z of the object.
			</p>
    		        <br />
            	        <center><img src="../img/portfolio/photo_z.png" width="700"></center>
                        <p style="FONT-SIZE:16px; COLOR:black; LINE-HEIGHT:20px; TEXT-ALIGN:justify;">
			We created a pipeline that takes raw images from SDSS, processes them to get science frames, extracts source
			pixels and redshifts for known sources. Then, with the help of this dataset, we train a nearest-neighbor
			algorithm to predict redshifts and classify into catagories like star, galaxy, QSO and background.
			</p>
                        <p style="FONT-SIZE:16px; COLOR:black; LINE-HEIGHT:20px; TEXT-ALIGN:justify;">
			First results from the method are encouraging. Plots of confusion matrices for both problems follow.
    		        </p>
    		        <br />
            	        <center><img src="../img/portfolio/photoz-regress.png" width="700"></center>
    		        <br />
            	        <center><img src="../img/portfolio/photoz-class.png" width="700"></center>
    		        <br />
                        <p style="FONT-SIZE:16px; COLOR:black; LINE-HEIGHT:20px; TEXT-ALIGN:justify;">
			Previously, we had trained a neural network to do the same thing over integrated sources. We also worked on
			redshifting spectra of available sources and finding the redshifted band magnitudes to create a nearly 10-fold
			expanded dataset. We achieved reasonable (~80%) accuracy in predicting redshifts when trained using the expanded 
			dataset.
			Implementation 
			<a target="_blank" href="http://www.github.com/alankarkotwal/image-photo-z">here</a>.
    		        </p>
                    </div>
                </div>
            </div>
        </div> <!-- end .container -->
    </body>
</html>
